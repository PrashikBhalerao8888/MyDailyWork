{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db3a450f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Step 1: Import necessary libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5790ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Load the dataset\n",
    "# We use the provided 'IMDb Movies India.csv' file for our data.\n",
    "try:\n",
    "    df = pd.read_csv('IMDb Movies India.csv', encoding='latin-1')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'IMDb Movies India.csv' not found. Please make sure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Original DataFrame (first 5 rows):\")\n",
    "print(df.head())\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce56cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data Preprocessing and Cleaning\n",
    "# Real-world data often requires cleaning before it can be used for modeling.\n",
    "\n",
    "# Drop unnecessary columns that won't be used as features.\n",
    "df.drop(['Name', 'Year', 'Duration', 'Votes'], axis=1, inplace=True)\n",
    "\n",
    "# Drop rows where 'Rating' is missing, as this is our target variable.\n",
    "df.dropna(subset=['Rating'], inplace=True)\n",
    "\n",
    "# Drop rows with any other missing feature values.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "# We will use 'Genre', 'Director', 'Actor 1', 'Actor 2', 'Actor 3' to predict 'Rating'.\n",
    "features = ['Genre', 'Director', 'Actor 1', 'Actor 2', 'Actor 3']\n",
    "target = 'Rating'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "print(f\"Dataset shape after cleaning: {df.shape}\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eaaf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split the data into training and testing sets\n",
    "# This is a crucial step to evaluate how well our model performs on unseen data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7d6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Preprocessing and Model Training Pipeline\n",
    "# We'll use a pipeline to combine preprocessing and the model into a single step.\n",
    "\n",
    "# First, define which columns are categorical. All our features are categorical.\n",
    "categorical_features = features\n",
    "\n",
    "# Create a preprocessor to apply one-hot encoding to the categorical features.\n",
    "# One-hot encoding converts categorical data into a numerical format that the model can understand.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Now, create the full pipeline with the preprocessor and a RandomForestRegressor model.\n",
    "# RandomForestRegressor is a good choice for this type of regression problem.\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
    "\n",
    "# Train the model using the training data.\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc46ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the model on the test data\n",
    "print(\"Evaluating the model on the test set...\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (RÂ²): {r2:.2f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d08a39cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Step 7: Make a prediction for a new, unseen movie\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Let's create a new movie data point based on the data we have.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# The model will use what it learned to predict the rating for this new movie.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m new_movie = \u001b[43mpd\u001b[49m.DataFrame({\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mGenre\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mAction\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mDirector\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mRohit Shetty\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mActor 1\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mAjay Devgn\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mActor 2\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mKareena Kapoor\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mActor 3\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mArshad Warsi\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m })\n\u001b[32m     12\u001b[39m predicted_rating = model.predict(new_movie)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFeatures of the new movie: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_movie.iloc[\u001b[32m0\u001b[39m].to_dict()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 7: Make a prediction for a new, unseen movie\n",
    "# Let's create a new movie data point based on the data we have.\n",
    "# The model will use what it learned to predict the rating for this new movie.\n",
    "new_movie = pd.DataFrame({\n",
    "    'Genre': ['Action'],\n",
    "    'Director': ['Rohit Shetty'],\n",
    "    'Actor 1': ['Ajay Devgn'],\n",
    "    'Actor 2': ['Kareena Kapoor'],\n",
    "    'Actor 3': ['Arshad Warsi']\n",
    "})\n",
    "\n",
    "predicted_rating = model.predict(new_movie)\n",
    "print(f\"Features of the new movie: {new_movie.iloc[0].to_dict()}\")\n",
    "print(f\"Predicted rating for the new movie: {predicted_rating[0]:.2f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# This script is a complete and self-contained example.\n",
    "# You can now save this file and run it directly with `python your_file_name.py`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
